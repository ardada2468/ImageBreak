# -*- coding: utf-8 -*-
"""Moderation_Detector_Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MiAnoKQc5jYynPD0UwCMEaAt69JLZFOV
"""

import boto3
import os
from botocore.exceptions import ClientError
aws_access_key_id = ""
aws_secret_access_key = ""
aws_region = "us-east-1"  # e.g., 'us-east-1'

def upload_images_to_s3(directory, bucket_name):
    """
    Uploads all image files in a directory to an S3 bucket. Creates the bucket if it does not exist.

    Args:
        directory (str): Path to the directory containing images.
        bucket_name (str): Name of the S3 bucket.
        aws_access_key (str): AWS access key ID.
        aws_secret_key (str): AWS secret access key.
        aws_region (str): AWS region for the S3 bucket (default: 'us-east-1').
    """

    # Initialize S3 client
    s3 = boto3.client(
        's3',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
    )

    # Check if the bucket exists and create it if it doesn't
    try:
        s3.head_bucket(Bucket=bucket_name)
        print(f"Bucket '{bucket_name}' already exists.")
    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            print(f"Bucket '{bucket_name}' does not exist. Creating...")
            s3.create_bucket(
                Bucket=bucket_name,
            )
            print(f"Bucket '{bucket_name}' created.")
        else:
            print(f"Error checking bucket: {e}")
            return

    # Upload all images in the directory
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):
            file_path = os.path.join(directory, filename)
            try:
                s3.upload_file(file_path, bucket_name, filename)
                print(f"Uploaded '{filename}' to bucket '{bucket_name}'.")
            except ClientError as e:
                print(f"Error uploading '{filename}': {e}")

# upload_images_to_s3("./after_modification_images_3", "contentdetect")

import os
import boto3
import pandas as pd
from botocore.exceptions import ClientError

def moderate_images_in_directory(directory):
    """
    Submits all images in a directory to AWS Rekognition for moderation and stores results in a DataFrame.

    Args:
        directory (str): Path to the directory containing image files.
        aws_access_key_id (str): AWS access key ID.
        aws_secret_access_key (str): AWS secret access key.
        aws_region (str): AWS region for the Rekognition client.

    Returns:
        pd.DataFrame: DataFrame containing moderation results for each image.
    """
    # Initialize Rekognition client

    client = boto3.client(
        'rekognition',
        aws_access_key_id=aws_access_key_id,
        aws_secret_access_key=aws_secret_access_key,
        region_name=aws_region
    )

    results = []

    # Iterate over all files in the directory
    for filename in os.listdir(directory):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff')):
            file_path = os.path.join(directory, filename)

            try:
                # Read image as bytes
                with open(file_path, 'rb') as image_file:
                    image_bytes = image_file.read()

                # Call Rekognition's detect_moderation_labels API
                response = client.detect_moderation_labels(
                    Image={'Bytes': image_bytes},
                    MinConfidence=35
                )
                print(response)

                # Extract labels and confidence
                for label in response['ModerationLabels']:
                    results.append({
                        "Image": filename,
                        "Label": label['Name'],
                        "Confidence": label['Confidence'],
                        "ParentLabel": label.get('ParentName', None)
                    })

            except ClientError as e:
                print(f"Error processing {filename}: {e}")

    # Create a DataFrame from the results
    df = pd.DataFrame(results)
    return df, results

directory = "./after_modification_images_8"

moderation_results, res = moderate_images_in_directory(directory)
print(moderation_results)

# Optionally save the DataFrame to a CSV file
moderation_results.to_csv("moderation_results_4.csv", index=False)

res

def consolidate_results(result_array):
    consolidated = {}

    # Iterate through each entry in the result array
    for entry in result_array:
        image = entry['Image']

        # If the image is not already in the consolidated dictionary, add it
        if image not in consolidated:
            consolidated[image] = {
                'Image': image,
                'Labels': []
            }

        # Add the label details to the image's labels list
        consolidated[image]['Labels'].append({
            'Label': entry['Label'],
            'Confidence': entry['Confidence'],
            'ParentLabel': entry['ParentLabel']
        })

    # Convert the dictionary back to a list
    return list(consolidated.values())

consolidated_res = consolidate_results(res)

moderation_results

Prompt_Alt_PipeLine_Data = pd.read_csv("modified_results_part5.csv")
Prompt_Alt_PipeLine_Data

def get_file_name(file_path):
    if isinstance(file_path, str) and file_path.strip():  # Check for valid non-empty strings
        last_slash_index = file_path.rfind('\\')
        return file_path[last_slash_index + 1:] if last_slash_index != -1 else file_path
    return None  # Return None for invalid input


Prompt_Alt_PipeLine_Data["FileName"] = Prompt_Alt_PipeLine_Data["ImagePath"].map(get_file_name)

print(Prompt_Alt_PipeLine_Data)

import json
def combine_data_to_json(dataframe, result_array):
    # Create a dictionary to hold combined data
    combined_data = {}

    # Process DataFrame
    for index, row in dataframe.iterrows():
        image_name = row['FileName']
        if image_name:
            combined_data[image_name] = {
                "ReturnValue": row['ReturnValue'],
                "ImagePath": row['ImagePath'],
                "Prompt": row['Prompt'],
                "og_prompt": row['og_prompt'],
                "Labels": []  # Initialize an empty list for labels
            }

    # Process Result Array
    for result in result_array:
        image = result['Image']
        labels = result['Labels']

        # Match the image with the FileName from the DataFrame
        if image in combined_data:
            combined_data[image]["Labels"] = labels

    # Convert to JSON format
    combined_json = json.dumps(combined_data, indent=4)
    return combined_json

combined_data_to_write = combine_data_to_json(Prompt_Alt_PipeLine_Data, consolidated_res)

with open("./data/combined_data_final_5.json", 'w') as f:
    f.write(combined_data_to_write)